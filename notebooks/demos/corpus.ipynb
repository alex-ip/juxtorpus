{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Corpus\n",
    "This notebook is entirely for `Corpus` and `SpacyCorpus` class.\n",
    "\n",
    "It will demonstrate how they are built and explore their functionalities and the more subtle accessors.\n",
    "\n",
    "Related classes:\n",
    "`Corpus`, `SpacyCorpus`, `CorpusBuilder`, `CorpusSlicer`, `SpacyProcessor`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'Working directory: /Users/hcha9747/workspace/juxtorpus'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if  not 'juxtorpus' in os.listdir():\n",
    "    os.chdir('../../')\n",
    "assert 'juxtorpus' in os.listdir(), f\"Working directory should be at juxtorpus. But at {os.getcwd()}\"\n",
    "f\"Working directory: {os.getcwd()}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Building a Corpus with CorpusBuilder\n",
    "\n",
    "Current limitations:\n",
    "- only accepts csv formats. (Please first write your own scripts to preprocess your data if required.)\n",
    "- multiple files requires them to share the same columns.\n",
    "\n",
    "Future:\n",
    "- more loading pipelines - accepting of formats aside from csv."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paths = [Path(\"./tests/assets/Geolocated_places_climate_with_LGA_and_remoteness_0.csv\"),\n",
    "         Path(\"./tests/assets/Geolocated_places_climate_with_LGA_and_remoteness_1.csv\")]\n",
    "for p in paths: assert p.exists()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "All Columns    day  geometry   year  tweet_lga  tweet_id  state_name_2016  \\\nAdd          False     False  False      False     False            False   \n\nAll Columns  state_code_2016  screen_name  retweet  remoteness  remote_level  \\\nAdd                    False        False    False       False         False   \n\nAll Columns  processed_text  month  lon_mid  lga_name_2020  lga_code_2020  \\\nAdd                   False  False    False          False          False   \n\nAll Columns  lat_mid  year_month_day  \nAdd            False           False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>All Columns</th>\n      <th>day</th>\n      <th>geometry</th>\n      <th>year</th>\n      <th>tweet_lga</th>\n      <th>tweet_id</th>\n      <th>state_name_2016</th>\n      <th>state_code_2016</th>\n      <th>screen_name</th>\n      <th>retweet</th>\n      <th>remoteness</th>\n      <th>remote_level</th>\n      <th>processed_text</th>\n      <th>month</th>\n      <th>lon_mid</th>\n      <th>lga_name_2020</th>\n      <th>lga_code_2020</th>\n      <th>lat_mid</th>\n      <th>year_month_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Add</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from juxtorpus.corpus import Corpus, CorpusBuilder\n",
    "\n",
    "builder = CorpusBuilder(paths)\n",
    "builder.show_columns().T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   year  month  day    lat_mid     lon_mid    screen_name      tweet_id  \\\n0  2019     11   29 -34.921620  138.598244    G_Westgarth  1.200000e+18   \n1  2019     12   30 -34.928770  138.599702  adelparklands  1.210000e+18   \n2  2020      1   29 -34.925639  138.600768     timklapdor  1.220000e+18   \n\n   retweet                                     processed_text  \\\n0    False  <TWEET> \"Merry Crisis\", \"You cannot eat money\"...   \n1    False  <TWEET> #adelaideparklands¬†#picoftheday¬†\\nThe ...   \n2    False  <TWEET> Same academics who would have their su...   \n\n                     geometry     tweet_lga  lga_code_2020 lga_name_2020  \\\n0    c(138.598244, -34.92162)  Adelaide (C)        40070.0  Adelaide (C)   \n1    c(138.599702, -34.92877)  Adelaide (C)        40070.0  Adelaide (C)   \n2  c(138.6007685, -34.925639)  Adelaide (C)        40070.0  Adelaide (C)   \n\n   state_code_2016  state_name_2016                 remoteness  remote_level  \\\n0              4.0  South Australia  Major Cities of Australia           1.0   \n1              4.0  South Australia  Major Cities of Australia           1.0   \n2              4.0  South Australia  Major Cities of Australia           1.0   \n\n  year_month_day  \n0     2019.11.29  \n1     2019.12.30  \n2      2020.1.29  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>lat_mid</th>\n      <th>lon_mid</th>\n      <th>screen_name</th>\n      <th>tweet_id</th>\n      <th>retweet</th>\n      <th>processed_text</th>\n      <th>geometry</th>\n      <th>tweet_lga</th>\n      <th>lga_code_2020</th>\n      <th>lga_name_2020</th>\n      <th>state_code_2016</th>\n      <th>state_name_2016</th>\n      <th>remoteness</th>\n      <th>remote_level</th>\n      <th>year_month_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019</td>\n      <td>11</td>\n      <td>29</td>\n      <td>-34.921620</td>\n      <td>138.598244</td>\n      <td>G_Westgarth</td>\n      <td>1.200000e+18</td>\n      <td>False</td>\n      <td>&lt;TWEET&gt; \"Merry Crisis\", \"You cannot eat money\"...</td>\n      <td>c(138.598244, -34.92162)</td>\n      <td>Adelaide (C)</td>\n      <td>40070.0</td>\n      <td>Adelaide (C)</td>\n      <td>4.0</td>\n      <td>South Australia</td>\n      <td>Major Cities of Australia</td>\n      <td>1.0</td>\n      <td>2019.11.29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019</td>\n      <td>12</td>\n      <td>30</td>\n      <td>-34.928770</td>\n      <td>138.599702</td>\n      <td>adelparklands</td>\n      <td>1.210000e+18</td>\n      <td>False</td>\n      <td>&lt;TWEET&gt; #adelaideparklands¬†#picoftheday¬†\\nThe ...</td>\n      <td>c(138.599702, -34.92877)</td>\n      <td>Adelaide (C)</td>\n      <td>40070.0</td>\n      <td>Adelaide (C)</td>\n      <td>4.0</td>\n      <td>South Australia</td>\n      <td>Major Cities of Australia</td>\n      <td>1.0</td>\n      <td>2019.12.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>29</td>\n      <td>-34.925639</td>\n      <td>138.600768</td>\n      <td>timklapdor</td>\n      <td>1.220000e+18</td>\n      <td>False</td>\n      <td>&lt;TWEET&gt; Same academics who would have their su...</td>\n      <td>c(138.6007685, -34.925639)</td>\n      <td>Adelaide (C)</td>\n      <td>40070.0</td>\n      <td>Adelaide (C)</td>\n      <td>4.0</td>\n      <td>South Australia</td>\n      <td>Major Cities of Australia</td>\n      <td>1.0</td>\n      <td>2020.1.29</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.head()     # loads to memory only the first n rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "builder.add_metas(['tweet_lga', 'screen_name'], dtypes='category')\n",
    "builder.add_metas('year_month_day', dtypes='datetime')  # this will keep meta id as 'year_month_day'\n",
    "builder.add_metas('remote_level')       # dtype is inferred by pandas.\n",
    "# note dtypes are pandas dtype, refer to their documentation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'<[/]?TWEET>')\n",
    "builder.set_text_preprocessors([lambda t: pattern.sub('', t).strip()])\n",
    "builder.set_text_column('processed_text')\n",
    "\n",
    "corpus = builder.build()        # now corpus is in memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[INFO] Building document-term matrix. Please wait...\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of corpus - incld. basic token level statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[INFO] Done.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Corpus Type Number of documents Number of terms Vocabulary size Terms mean  \\\n0      Corpus               20000          486127           35943   24.30635   \n\n   Terms std Terms min Terms 25% Terms 50% Terms 75% Terms max  \\\n0  16.313522       0.0      11.0      22.0      37.0     111.0   \n\n                                               metas  \n0  tweet_lga, screen_name, year_month_day, remote...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Corpus Type</th>\n      <th>Number of documents</th>\n      <th>Number of terms</th>\n      <th>Vocabulary size</th>\n      <th>Terms mean</th>\n      <th>Terms std</th>\n      <th>Terms min</th>\n      <th>Terms 25%</th>\n      <th>Terms 50%</th>\n      <th>Terms 75%</th>\n      <th>Terms max</th>\n      <th>metas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Corpus</td>\n      <td>20000</td>\n      <td>486127</td>\n      <td>35943</td>\n      <td>24.30635</td>\n      <td>16.313522</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>22.0</td>\n      <td>37.0</td>\n      <td>111.0</td>\n      <td>tweet_lga, screen_name, year_month_day, remote...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summary of corpus - incld. basic token level statistics\")\n",
    "corpus.summary().to_frame().T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the meta data in the corpus.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         dtype               sample  \\\ntweet_lga               object         Adelaide (C)   \nscreen_name             object          G_Westgarth   \nyear_month_day  datetime64[ns]  2019-11-29 00:00:00   \nremote_level           float64                  1.0   \n\n                                         mean                          std  \\\ntweet_lga                                 NaN                          NaN   \nscreen_name                               NaN                          NaN   \nyear_month_day  2020-07-16 05:05:25.439999744  255 days 23:34:42.676885548   \nremote_level                         1.471865                     0.734378   \n\n                                min                  25%                  50%  \\\ntweet_lga                       NaN                  NaN                  NaN   \nscreen_name                     NaN                  NaN                  NaN   \nyear_month_day  2019-11-11 00:00:00  2020-01-02 00:00:00  2020-02-22 00:00:00   \nremote_level                    1.0                  1.0                  1.0   \n\n                                75%                  max  top  top_freq  \\\ntweet_lga                       NaN                  NaN  NaN       NaN   \nscreen_name                     NaN                  NaN  NaN       NaN   \nyear_month_day  2021-01-03 00:00:00  2022-04-12 00:00:00  NaN       NaN   \nremote_level                    2.0                  5.0  1.0   12691.0   \n\n                                         uniqs  num_uniqs  \ntweet_lga                                  NaN        NaN  \nscreen_name                                NaN        NaN  \nyear_month_day                             NaN        NaN  \nremote_level    [1.0, 3.0, 2.0, 5.0, 4.0, nan]        6.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dtype</th>\n      <th>sample</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>top</th>\n      <th>top_freq</th>\n      <th>uniqs</th>\n      <th>num_uniqs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tweet_lga</th>\n      <td>object</td>\n      <td>Adelaide (C)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>screen_name</th>\n      <td>object</td>\n      <td>G_Westgarth</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>year_month_day</th>\n      <td>datetime64[ns]</td>\n      <td>2019-11-29 00:00:00</td>\n      <td>2020-07-16 05:05:25.439999744</td>\n      <td>255 days 23:34:42.676885548</td>\n      <td>2019-11-11 00:00:00</td>\n      <td>2020-01-02 00:00:00</td>\n      <td>2020-02-22 00:00:00</td>\n      <td>2021-01-03 00:00:00</td>\n      <td>2022-04-12 00:00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>remote_level</th>\n      <td>float64</td>\n      <td>1.0</td>\n      <td>1.471865</td>\n      <td>0.734378</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>12691.0</td>\n      <td>[1.0, 3.0, 2.0, 5.0, 4.0, nan]</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summary of the meta data in the corpus.\")\n",
    "corpus.meta.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                count                          mean        min        25%  \\\nyear_month_day  20000 2020-07-16 05:05:25.439999744 2019-11-11 2020-01-02   \n\n                      50%        75%        max  \nyear_month_day 2020-02-22 2021-01-03 2022-04-12  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>year_month_day</th>\n      <td>20000</td>\n      <td>2020-07-16 05:05:25.439999744</td>\n      <td>2019-11-11</td>\n      <td>2020-01-02</td>\n      <td>2020-02-22</td>\n      <td>2021-01-03</td>\n      <td>2022-04-12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing series of the metadata series directly.\n",
    "corpus.meta.get('year_month_day').series().describe(datetime_is_numeric=True).to_frame().T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Slicing the Corpus\n",
    "\n",
    "The preferred way to slice the corpus is to access the `.slicer` property in Corpus. This will allow you to chain multiple slicing operations together.\n",
    "\n",
    "Otherwise, you may wish to import `CorpusSlicer` and slice it that way. `.slicer` really just uses `CorpusSlicer` underneath the hood."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[INFO] Converted start datetime : 2020y 01m 01d 00:00:00\u001B[0m\n",
      "\u001B[32m[INFO] Converted end datetime   : 2021y 01m 01d 00:00:00\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "twentytwenty: Corpus = corpus.slicer.filter_by_datetime('year_month_day', start='01-01-2020', end='01-01-2021', strftime=\"%d-%m-%y\")\n",
    "\n",
    "# from juxtorpus.corpus import CorpusSlicer\n",
    "# twentytwenty = CorpusSlicer(corpus).filter_by_datetime('year_month_day', start='01-01-2020', end='01-01-2021', strftime=\"%d-%m-%y\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  Corpus Type Number of documents Number of terms Vocabulary size Terms mean  \\\n0      Corpus               10134          240010           23013  23.683639   \n\n   Terms std Terms min Terms 25% Terms 50% Terms 75% Terms max  \\\n0  15.843954       0.0      11.0      21.0      37.0     107.0   \n\n                                               metas  \n0  tweet_lga, screen_name, year_month_day, remote...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Corpus Type</th>\n      <th>Number of documents</th>\n      <th>Number of terms</th>\n      <th>Vocabulary size</th>\n      <th>Terms mean</th>\n      <th>Terms std</th>\n      <th>Terms min</th>\n      <th>Terms 25%</th>\n      <th>Terms 50%</th>\n      <th>Terms 75%</th>\n      <th>Terms max</th>\n      <th>metas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Corpus</td>\n      <td>10134</td>\n      <td>240010</td>\n      <td>23013</td>\n      <td>23.683639</td>\n      <td>15.843954</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>21.0</td>\n      <td>37.0</td>\n      <td>107.0</td>\n      <td>tweet_lga, screen_name, year_month_day, remote...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the summary() again for this sliced corpus.\n",
    "twentytwenty.summary().to_frame().T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adelaide (C)                  \t8    documents\n",
      "Adelaide Hills (DC)           \t8    documents\n",
      "Albany (C)                    \t16   documents\n",
      "Albury (C)                    \t48   documents\n",
      "Alexandrina (DC)              \t252  documents\n"
     ]
    },
    {
     "data": {
      "text/plain": "Corpus Type                                                       Corpus\nNumber of documents                                                  252\nNumber of terms                                                     4630\nVocabulary size                                                     1045\nTerms mean                                                     18.373016\nTerms std                                                      15.232976\nTerms min                                                            0.0\nTerms 25%                                                            5.0\nTerms 50%                                                           12.0\nTerms 75%                                                           31.0\nTerms max                                                           55.0\nmetas                  tweet_lga, screen_name, year_month_day, remote...\ndtype: object"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's group by the tweet_lgas\n",
    "\n",
    "groups = list(twentytwenty.slicer.group_by('tweet_lga'))\n",
    "for gid, group in groups[:5]:\n",
    "    print(f\"{gid.ljust(30)}\\t{str(len(group)).ljust(4)} documents\")\n",
    "\n",
    "alexandrina = groups[4][1]\n",
    "alexandrina.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['HeatherHalstead', 'SophiaMcGrane', 'SullJack48'], dtype=object)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see\n",
    "screen_names = alexandrina.meta.get('screen_name').series().unique()\n",
    "screen_names[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Number of documents with a screen name that is HeatherHalstead' = 4\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's filter for 'remote_level'\n",
    "num = len(alexandrina.slicer.filter_by_item('screen_name', screen_names[0]))\n",
    "f\"Number of documents with a screen name that is HeatherHalstead' = {num}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Number of documents with a screen name that starts with 'H' or 'S' = 240\""
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most flexible slicing is via filter_by_condition\n",
    "import re\n",
    "num = len(alexandrina.slicer.filter_by_condition('screen_name', lambda name: re.match(r'^[HS].+', name) is not None))\n",
    "\n",
    "f\"Number of documents with a screen name that starts with 'H' or 'S' = {num}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Document-Term Matrix DTM\n",
    "\n",
    "Every Corpus allows you to access its `.dtm`. The `DTM` object that it returns houses a sparse matrix and exposes numerous functions for you to do further downstream analysis. The matrix is built using sklearn's `CountVectorizer`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(<DTM 252 docs X 35943 terms>,\n (252, 35943),\n <252x35943 sparse matrix of type '<class 'numpy.int64'>'\n \twith 4208 stored elements in Compressed Sparse Row format>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexandrina.dtm, alexandrina.dtm.shape, alexandrina.dtm.matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['10mins', '10mm_404', '10newsfirst', '10newsfirstmelb',\n       '10newsfirstqld'], dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexandrina.dtm.term_names[125:130]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(4630, 4630)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a FreqTable of the dtm\n",
    "alexandrina.dtm.total, alexandrina.dtm.freq_table().total"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "((252, 35943), (252, 35943))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a new DTM with TFIDF values\n",
    "tfidf = alexandrina.dtm.tfidf(use_idf=True, smooth_idf=True)   # pass in sklearn args\n",
    "\n",
    "assert id(alexandrina.dtm) != id(tfidf), \"TFIDF DTM is a new copy.\"\n",
    "alexandrina.dtm.shape, tfidf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SpacyCorpus\n",
    "\n",
    "In NLP, we'll want to go a step further and perform tasks such as POS tagging, lemmatisation, entity extraction etc.\n",
    "\n",
    "We have decided to use spacy as our dependency for these tasks due to its extendability and is feature rich out of the box.\n",
    "\n",
    "Please note spacy's `Doc` objects are relatively expensive on the memory due to all the information that it stores. You can alleviate this by excluding components from spacy pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Building a SpacyCorpus\n",
    "\n",
    "The preferred way to process a Corpus into SpacyCorpus is by using the `process()` function.\n",
    "This is a factory method that chooses whichever processor is appropriate given the keyword arguments kwargs. (Although we currently only support spacy)\n",
    "\n",
    "NOTE: Please `detached()` a subcorpus first before processing with spacy due to index misalignment issues. This will be fixed in a later release."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "alexandrina = alexandrina.detached()\n",
    "\n",
    "# NOTE: this is a workaround - issues:\n",
    "# DTM is rebuilt after processing, therefore the indexing is misaligned.\n",
    "# detached() will make corpus a root corpus and process starts as new."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[INFO] Processing corpus of 252 documents...\u001B[0m\n",
      "\u001B[32m[INFO] Done.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from juxtorpus.corpus.processors import process\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', exclude=['ner'])\n",
    "scorpus = process(alexandrina, nlp=nlp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[INFO] Building document-term matrix. Please wait...\u001B[0m\n",
      "\u001B[32m[INFO] Done.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                          0\nlang                                                     en\nmodel                                           core_web_sm\npipeline  tok2vec, tagger, parser, attribute_ruler, lemm...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lang</th>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>model</th>\n      <td>core_web_sm</td>\n    </tr>\n    <tr>\n      <th>pipeline</th>\n      <td>tok2vec, tagger, parser, attribute_ruler, lemm...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary, spacy_info = scorpus.summary(spacy=True)\n",
    "spacy_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will notice some subtle differences in the statistics of the original Corpus v.s. SpacyCorpus.\n",
    "This is due to the difference in tokenisations methods used. SpacyCorpus uses spacy's tokenisation method. This is to be expected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[INFO] Building document-term matrix. Please wait...\u001B[0m\n",
      "\u001B[32m[INFO] Done.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                                     0  \\\nCorpus Type                                                     Corpus   \nNumber of documents                                                252   \nNumber of terms                                                   4630   \nVocabulary size                                                   1045   \nTerms mean                                                   18.373016   \nTerms std                                                    15.232976   \nTerms min                                                          0.0   \nTerms 25%                                                          5.0   \nTerms 50%                                                         12.0   \nTerms 75%                                                         31.0   \nTerms max                                                         55.0   \nmetas                tweet_lga, screen_name, year_month_day, remote...   \n\n                                                                     1  \nCorpus Type                                                SpacyCorpus  \nNumber of documents                                                252  \nNumber of terms                                                   4352  \nVocabulary size                                                    957  \nTerms mean                                                   17.269841  \nTerms std                                                    14.599248  \nTerms min                                                          0.0  \nTerms 25%                                                          5.0  \nTerms 50%                                                         11.0  \nTerms 75%                                                         29.0  \nTerms max                                                         52.0  \nmetas                tweet_lga, screen_name, year_month_day, remote...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Corpus Type</th>\n      <td>Corpus</td>\n      <td>SpacyCorpus</td>\n    </tr>\n    <tr>\n      <th>Number of documents</th>\n      <td>252</td>\n      <td>252</td>\n    </tr>\n    <tr>\n      <th>Number of terms</th>\n      <td>4630</td>\n      <td>4352</td>\n    </tr>\n    <tr>\n      <th>Vocabulary size</th>\n      <td>1045</td>\n      <td>957</td>\n    </tr>\n    <tr>\n      <th>Terms mean</th>\n      <td>18.373016</td>\n      <td>17.269841</td>\n    </tr>\n    <tr>\n      <th>Terms std</th>\n      <td>15.232976</td>\n      <td>14.599248</td>\n    </tr>\n    <tr>\n      <th>Terms min</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Terms 25%</th>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>Terms 50%</th>\n      <td>12.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>Terms 75%</th>\n      <td>31.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>Terms max</th>\n      <td>55.0</td>\n      <td>52.0</td>\n    </tr>\n    <tr>\n      <th>metas</th>\n      <td>tweet_lga, screen_name, year_month_day, remote...</td>\n      <td>tweet_lga, screen_name, year_month_day, remote...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.concat([alexandrina.summary(), summary], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Slicing a SpacyCorpus\n",
    "\n",
    "Slicing a spacy corpus is just like slicing a Corpus. However, you may also choose to use [spacy's Matchers](https://spacy.io/usage/rule-based-matching).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "('HeatherHalstead', array(['HeatherHalstead'], dtype=object))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo: previous filter_by_item\n",
    "sliced = scorpus.slicer.filter_by_item('screen_name', screen_names[0])\n",
    "screen_names[0], sliced.meta.get('screen_name').series().unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# demo: new filter_by_matcher\n",
    "from juxtorpus.matchers import hashtags\n",
    "matcher = hashtags(scorpus.nlp.vocab)            # predefined matcher\n",
    "ht = scorpus.slicer.filter_by_matcher(matcher)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Corpus Type                                                  SpacyCorpus\nNumber of documents                                                   10\nNumber of terms                                                      267\nVocabulary size                                                      169\nTerms mean                                                          26.7\nTerms std                                                      13.106826\nTerms min                                                            1.0\nTerms 25%                                                          24.75\nTerms 50%                                                           28.0\nTerms 75%                                                           31.0\nTerms max                                                           44.0\nmetas                  tweet_lga, screen_name, year_month_day, remote...\ndtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are all the documents containing at least one hashtag.\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "as soon as the questions from the media pack turned to action on the climate emergency, Morrison abruptly ends questions and walks off #fuckwit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Calling out all Liberal Staffers- if you think the PMs latest presser is a success please realise it's a fail. Arsonists National Parks Jenny Not addressing Climate Change Smirking- Big Fail #ScoMoResign #ScottMorrison #AustraliaBushfires\n",
      "----------------------------------------------------------------------------------------------------\n",
      "there is no point in relying just on 'adaptation' ffs..\n",
      "there is a limit to how much 'adaptation' there can be to the rapidly escalating human caused climate change emergency we are experiencing right now! adaptation on its own WILL NOT SAVE US  #qanda\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#insiders\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Climate change will cost more lives and money than #COVID19 if we don't take radical action. Not meeting climate targets could cost us trillions <https://t.co/dYYspiLYmF> #science via @CosmosMagazine #ClimateEmergency #RenewableEnergy\n",
      "----------------------------------------------------------------------------------------------------\n",
      "and very disappointing that #qanda have bought into this false dichotomy\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Emissions dropped by 17% during the #pandemic - but it means nothing if we don't make changes moving forward. How a pandemic created a cleaner planet <https://t.co/IqD31qQxfg> #science via @CosmosMagazine @clequere #ClimateAction #emissions\n",
      "----------------------------------------------------------------------------------------------------\n",
      "so just so all youse #abc730 viewers know..\n",
      "Michael Penguilly is a climate change denier of the likes of Craig Kelly.. also.. Penguilly is a vile misogynist.. just google\n",
      "----------------------------------------------------------------------------------------------------\n",
      "seriously @abc730.. did you even bother to speak to anyone with differing views other than that bunch of climate change deniers you gave an exclusive platform to?\n",
      "#ThisIsNotJournalism #abc730 #kangarooisland\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@deniseshrivell I'm crying Denise..\n",
      "üëâüèºToday is The Day Democracy Wins For Everyone\n",
      "üëâüèºToday is The Day The World Gets Back to Work on Tackling the Catastrophic Climate Change Emergency\n",
      "üëâüèºToday is The Day the Whole World Wins\n",
      "\n",
      "and I could not be happier in this moment in time..\n",
      "#BidenHarris2020\n"
     ]
    }
   ],
   "source": [
    "print(\"These are all the documents containing at least one hashtag.\")\n",
    "print(\"=\"*100)\n",
    "for doc in ht:\n",
    "    print(\"-\"*100)\n",
    "    print(doc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
