{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Memory Benchmarks\n",
    "\n",
    "1. exclusion of spacy components in pipeline\n",
    "2. stream writes\n",
    "3. str(np.object) -> pyarrow str -> categorical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 285.05 MiB, increment: 77.94 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 346.45 MiB, increment: 61.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "import pandas as pd\n",
    "\n",
    "texts = pd.read_csv('~/Downloads/Geolocated_places_climate_with_LGA_and_remoteness_with_text.csv', usecols=['text'],\n",
    "                    nrows=10_000).loc[:, 'text']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1278.61 MiB, increment: 932.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# docs object all components included.\n",
    "docs = list(nlp.pipe(texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1290.73 MiB, increment: 12.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "nlp_lite = spacy.load('en_core_web_sm', exclude=['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1381.58 MiB, increment: 92.88 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "docs2 = list(nlp_lite.pipe(texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Persisting to Disk (Stream)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'<TWEET> \"Merry Crisis\", \"You cannot eat money\", \"Coal bludger\", just some of the messages on show at the Solidarity Sit-Down outside Parliament House. The activists protesting over climate change inaction, they say is contributing to catastrophic bushfire conditions. @9NewsAdel <https://t.co/6qaEHbIXy5> </TWEET>'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "processed = texts.apply(lambda x: re.sub('\\n', '', x))\n",
    "processed.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "processed.to_csv('/tmp/Geo_texts.txt', index=False, header=None, sep=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# %%memit\n",
    "def stream(path: str):\n",
    "    with open(path, 'r') as h:\n",
    "        for line in h:\n",
    "            yield line\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1385.61 MiB, increment: 1.58 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "for doc in nlp_lite.pipe(stream(\"/tmp/Geo_texts.txt\")):\n",
    "    continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1385.77 MiB, increment: 0.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "with open(\"/tmp/Geo_texts_processeed.txt\", 'w') as h:\n",
    "    for doc in nlp_lite.pipe(stream(\"/tmp/Geo_texts.txt\")):\n",
    "        h.write(f\"{len(doc)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorical dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1380.27 MiB, increment: -2.22 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "tweet_lgas = pd.read_csv('~/Downloads/Geolocated_places_climate_with_LGA_and_remoteness_with_text.csv', usecols=['tweet_lga'],\n",
    "                    nrows=10_000)\n",
    "# the supposed categorical column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'Tweet_lga (np.object) uses 0.696822 mbytes.'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_bytes = tweet_lgas.memory_usage(deep=True).loc['tweet_lga']\n",
    "\n",
    "f\"Tweet_lga (np.object) uses {obj_bytes/1_000_000} mbytes.\" # default str in pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'Tweet_lga (pyarrow) uses 0.166822 mbytes.'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_bytes = tweet_lgas.astype(dtype=\"string[pyarrow]\").memory_usage(deep=True).loc['tweet_lga']\n",
    "f\"Tweet_lga (pyarrow) uses {str_bytes/1_000_000} mbytes.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'Tweet_lga (categorical) uses 0.021616 mbytes.'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_bytes = tweet_lgas.astype(dtype='category').memory_usage(deep=True).loc['tweet_lga']\n",
    "f\"Tweet_lga (categorical) uses {cat_bytes/1_000_000} mbytes.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "'From obj -> categorical: ~ 32.24x'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"From obj -> categorical: ~{obj_bytes/cat_bytes: .2f}x\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'That was for 10000 rows. Scaling that to 10x10^6 rows would be 696.822 mbytes in obj; 21.7756875 mbytes in categorical'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"That was for {10_000} rows. Scaling that to 10x10^6 rows would be {obj_bytes/10_00} mbytes in obj; {obj_bytes/10_00/32} mbytes in categorical\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
